{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from triplet_image_loader import TripletImageLoader\n",
    "from tripletnet import TripletNet\n",
    "from visdom import Visdom\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_image_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "class TripletImageLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_path, filenames_filename, triplets_file_name, transform=None,\n",
    "                 loader=default_image_loader):\n",
    "        \"\"\" filenames_filename: A text file with each line containing the path to an image e.g.,\n",
    "                images/class1/sample.jpg\n",
    "            triplets_file_name: A text file with each line containing three integers, \n",
    "                where integer i refers to the i-th image in the filenames file. \n",
    "                For a line of intergers 'a b c', a triplet is defined such that image a is more \n",
    "                similar to image c than it is to image b, e.g., \n",
    "                0 2017 42 \"\"\"\n",
    "        self.base_path = base_path  \n",
    "        self.filenamelist = []\n",
    "        for line in open(filenames_filename):\n",
    "            self.filenamelist.append(line.rstrip('\\n'))\n",
    "        triplets = []\n",
    "        for line in open(triplets_file_name):\n",
    "            triplets.append((line.split()[0], line.split()[1], line.split()[2])) # anchor, far, close\n",
    "        self.triplets = triplets\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path1, path2, path3 = self.triplets[index]\n",
    "        img1 = self.loader(os.path.join(self.base_path,self.filenamelist[int(path1)]))\n",
    "        img2 = self.loader(os.path.join(self.base_path,self.filenamelist[int(path2)]))\n",
    "        img3 = self.loader(os.path.join(self.base_path,self.filenamelist[int(path3)]))\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "            img3 = self.transform(img3)\n",
    "\n",
    "        return img1, img2, img3\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embeddingnet):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embeddingnet = embeddingnet\n",
    "\n",
    "    def forward(self, x, y, z):\n",
    "        embedded_x = self.embeddingnet(x)\n",
    "        embedded_y = self.embeddingnet(y)\n",
    "        embedded_z = self.embeddingnet(z)\n",
    "        dist_a = F.pairwise_distance(embedded_x, embedded_y, 2)\n",
    "        dist_b = F.pairwise_distance(embedded_x, embedded_z, 2)\n",
    "        return dist_a, dist_b, embedded_x, embedded_y, embedded_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, tnet, criterion, optimizer, epoch):\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "    emb_norms = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    tnet.train()\n",
    "    for batch_idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "        data1, data2, data3 = Variable(data1), Variable(data2), Variable(data3)\n",
    "\n",
    "        # compute output\n",
    "        dista, distb, embedded_x, embedded_y, embedded_z = tnet(data1, data2, data3)\n",
    "        # 1 means, dista should be larger than distb\n",
    "        target = torch.FloatTensor(dista.size()).fill_(1)\n",
    "        if args.cuda:\n",
    "            target = target.cuda()\n",
    "        target = Variable(target)\n",
    "        \n",
    "        loss_triplet = criterion(dista, distb, target)\n",
    "        loss_embedd = embedded_x.norm(2) + embedded_y.norm(2) + embedded_z.norm(2)\n",
    "        loss = loss_triplet + 0.001 * loss_embedd\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy(dista, distb)\n",
    "        losses.update(loss_triplet.data[0], data1.size(0))\n",
    "        accs.update(acc, data1.size(0))\n",
    "        emb_norms.update(loss_embedd.data[0]/3, data1.size(0))\n",
    "\n",
    "        # compute gradient and do optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\t'\n",
    "                  'Loss: {:.4f} ({:.4f}) \\t'\n",
    "                  'Acc: {:.2f}% ({:.2f}%) \\t'\n",
    "                  'Emb_Norm: {:.2f} ({:.2f})'.format(\n",
    "                epoch, batch_idx * len(data1), len(train_loader.dataset),\n",
    "                losses.val, losses.avg, \n",
    "                100. * accs.val, 100. * accs.avg, emb_norms.val, emb_norms.avg))\n",
    "    # log avg values to somewhere\n",
    "    plotter.plot('acc', 'train', epoch, accs.avg)\n",
    "    plotter.plot('loss', 'train', epoch, losses.avg)\n",
    "    plotter.plot('emb_norms', 'train', epoch, emb_norms.avg)\n",
    "\n",
    "def test(test_loader, tnet, criterion, epoch):\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    tnet.eval()\n",
    "    for batch_idx, (data1, data2, data3) in enumerate(test_loader):\n",
    "        if args.cuda:\n",
    "            data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "        data1, data2, data3 = Variable(data1), Variable(data2), Variable(data3)\n",
    "\n",
    "        # compute output\n",
    "        dista, distb, _, _, _ = tnet(data1, data2, data3)\n",
    "        target = torch.FloatTensor(dista.size()).fill_(1)\n",
    "        if args.cuda:\n",
    "            target = target.cuda()\n",
    "        target = Variable(target)\n",
    "        test_loss =  criterion(dista, distb, target).data[0]\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy(dista, distb)\n",
    "        accs.update(acc, data1.size(0))\n",
    "        losses.update(test_loss, data1.size(0))      \n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\n",
    "        losses.avg, 100. * accs.avg))\n",
    "    plotter.plot('acc', 'test', epoch, accs.avg)\n",
    "    plotter.plot('loss', 'test', epoch, losses.avg)\n",
    "    return accs.avg\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    \"\"\"Saves checkpoint to disk\"\"\"\n",
    "    directory = \"runs/%s/\"%(args.name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = directory + filename\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'runs/%s/'%(args.name) + 'model_best.pth.tar')\n",
    "\n",
    "class VisdomLinePlotter(object):\n",
    "    \"\"\"Plots to Visdom\"\"\"\n",
    "    def __init__(self, env_name='main'):\n",
    "        self.viz = Visdom()\n",
    "        self.env = env_name\n",
    "        self.plots = {}\n",
    "    def plot(self, var_name, split_name, x, y):\n",
    "        if var_name not in self.plots:\n",
    "            self.plots[var_name] = self.viz.line(X=np.array([x,x]), Y=np.array([y,y]), env=self.env, opts=dict(\n",
    "                legend=[split_name],\n",
    "                title=var_name,\n",
    "                xlabel='Epochs',\n",
    "                ylabel=var_name\n",
    "            ))\n",
    "        else:\n",
    "            self.viz.updateTrace(X=np.array([x]), Y=np.array([y]), env=self.env, win=self.plots[var_name], name=split_name)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(dista, distb):\n",
    "    margin = 0\n",
    "    pred = (dista - distb - margin).cpu().data\n",
    "    return (pred > 0).sum()*1.0/dista.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global args, best_acc = 0\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=20, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--margin', type=float, default=0.2, metavar='M',\n",
    "                    help='margin for triplet loss (default: 0.2)')\n",
    "parser.add_argument('--resume', default='', type=str,\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--name', default='TripletNet', type=str,\n",
    "                    help='name of experiment')\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "global plotter \n",
    "plotter = VisdomLinePlotter(env_name=args.name)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    TripletImageLoader('../data', 'imagelist.txt', 'behind_train_triplets.json',\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    TripletImageLoader('../data', 'imagelist.txt', 'behind_test_triplets.json', transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = Net()\n",
    "tnet = TripletNet(model)\n",
    "if args.cuda:\n",
    "    tnet.cuda()\n",
    "\n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        tnet.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "criterion = torch.nn.MarginRankingLoss(margin = args.margin)\n",
    "optimizer = optim.SGD(tnet.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "n_parameters = sum([p.data.nelement() for p in tnet.parameters()])\n",
    "print('  + Number of params: {}'.format(n_parameters))\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    # train for one epoch\n",
    "    train(train_loader, tnet, criterion, optimizer, epoch)\n",
    "    # evaluate on validation set\n",
    "    acc = test(test_loader, tnet, criterion, epoch)\n",
    "\n",
    "    # remember best acc and save checkpoint\n",
    "    is_best = acc > best_acc\n",
    "    best_acc = max(acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': tnet.state_dict(),\n",
    "        'best_prec1': best_acc,\n",
    "    }, is_best)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
